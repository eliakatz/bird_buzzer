{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c52394b",
   "metadata": {},
   "source": [
    "# Bird's Selective Buzzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e19f77",
   "metadata": {},
   "source": [
    "## Abstract:\n",
    "\n",
    "Birds like to come to the balcony. There are birds like the sunbird that come to suck the nectar from the flowers, swing and play on the plants and fly away. But, there are birds like the mynas and crows which are aggressive and terribly noisy (especially when they start nesting), and doves that leave a disastrous mess until their fledglings leave the nest.\n",
    "\n",
    "***The problem:*** \n",
    "* How to drive away only the problematic birds?\n",
    "\n",
    "***The solution:***\n",
    "* A selective buzzer that buzzes only when an unwelcome bird arrives (dove, myna, and crow).\n",
    "\n",
    "**Stage 1:** \n",
    "* Training a Machine learning model to classify the birds by their sounds.\n",
    "* Binary classifying the birds (buzzer activator or not).\n",
    "\n",
    "**Stage 2:**\n",
    "* Building a buzzer that makes noise when a problematic bird arrives.\n",
    "* Sending the order to activate according to the results of the classification.\n",
    "\n",
    "***Available data:***\n",
    "* Birds' sounds from [xeno-canto.org](https://xeno-canto.org).\n",
    "\n",
    "***Potential users:***\n",
    "* Anyone who wants to drive away birds selectively from the balcony, building, field etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2c2b3a",
   "metadata": {},
   "source": [
    "## Work plan\n",
    "\n",
    "### Prepare the data:\n",
    "* Import audio files from [xeno-canto.org](https://xeno-canto.org).\n",
    "* Preprocessing the audio files using [Audacity](https://www.audacityteam.org): \n",
    "    - Cut silent parts in the beginning of the audio file.\n",
    "    - Duplicate parts in the short files to have duration of at least 3 sec.\n",
    "    - Reduce background noise.\n",
    "    - Expand the amplitude envelope where needed.\n",
    "    - *note:* The original files are recorded in different channel mode, sample rate, duration, quality, environments etc. \n",
    "* Format the files as *.wav* - The processing audio libraries use wav format.\n",
    "* Build a dataframe of the files, short file name (index) and the bird's class.\n",
    "* Load the audio files set to equal channels (mono), sample rate (44100), and duration (3 sec).\n",
    "\n",
    "\n",
    "### EDA\n",
    "* Visualize some samples of each type.\n",
    "* Check the data\n",
    "* Set the parameters for comparison.\n",
    "* Encode the categorcial features.\n",
    "* Scale the numeric features (train only) and transform it to all sets.\n",
    "* Check outliers.\n",
    "\n",
    "### Models:\n",
    "* Due to the low amount of samples - a neural network cannot be used. The training will be done in traditional ML, using feature engineering.\n",
    "* Baseline model - A constant (True).\n",
    "* Logistic regression\n",
    "* Decision tree classifier (with upsample, downsample and threshold)\n",
    "* Random forest\n",
    "* Cross validation\n",
    "\n",
    "### Conclusions\n",
    "* Overall conclusions.\n",
    "\n",
    "### Run the model on a Raspberry Pi\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5348bd1",
   "metadata": {},
   "source": [
    "## Inisialization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942c078a",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43768e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import scipy as sp\n",
    "import scipy.fft as spf\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics as skm \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ipywidgets as widgets #buttons for contitional execution\n",
    "from ipywidgets import interact, interact_manual\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from joblib import dump\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a1cc9",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "LOCAL_PATH = 'G:\\Eliana\\Documents\\Data Science\\CA\\Project booster\\\\'\n",
    "LOCAL_PATH_MP3 = LOCAL_PATH + 'mp3\\\\' # path to the mp3 folder\n",
    "LOCAL_PATH_WAV = LOCAL_PATH + 'wav\\\\' # path to the wav folder\n",
    "BIRDS = ['sunbird', 'dove', 'myna', 'crow'] # the species of the birds\n",
    "RAND_STATE = 12 # random state\n",
    "SR=44100 # sample rate=44100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec7ecb",
   "metadata": {},
   "source": [
    "### Buttons for conditional executes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01eb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create execution buttons\n",
    "btn_conv = widgets.Button(description = 'Convert files to wav') # 'Convert files to .wav'\n",
    "btn_time = widgets.Button(description = 'Plot waves') # 'Plot waves'\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_conv_clicked(b):\n",
    "    convert_mp3_to_wav()\n",
    "    \n",
    "def on_btn_time_clicked(b):\n",
    "    plot_waves()\n",
    "    \n",
    "    \n",
    "# on_click events:\n",
    "btn_conv.on_click(on_conv_clicked)\n",
    "btn_time.on_click(on_btn_time_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de07df9f",
   "metadata": {},
   "source": [
    "### Convert mp3 files to wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc370ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files in mp3 directory\n",
    "\n",
    "files = os.listdir(LOCAL_PATH + 'mp3\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4480247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mp3 files to wav. \n",
    "def convert_mp3_to_wav():\n",
    "    \"\"\"Convert the mp3 files to wav. The fuction is executed by pressing the button below, as there's no need\n",
    "    to repeat it once the files are converted and there are no changes in the original mp3s\"\"\"\n",
    "    \n",
    "    print('converting...')\n",
    "    for file in files:\n",
    "        src = LOCAL_PATH_MP3 + file\n",
    "        dst = LOCAL_PATH_WAV + file.replace('mp3', 'wav')\n",
    "\n",
    "        try:\n",
    "            # convert mp3 to wav                                                            \n",
    "            sound = AudioSegment.from_mp3(src)\n",
    "            wav_file=sound.export(dst, format=\"wav\")\n",
    "            wav_file.close()      \n",
    "        except:\n",
    "            print('Error converting', file)\n",
    "            continue\n",
    "\n",
    "# diaplay the execution button            \n",
    "display(btn_conv, output) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4cbf4a",
   "metadata": {},
   "source": [
    "### List the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a289535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the files\n",
    "files_wav = os.listdir(LOCAL_PATH_WAV)\n",
    "files_wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b705a",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db69e169",
   "metadata": {},
   "source": [
    "#### Load audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio files\n",
    "def load_audio(path, filename):\n",
    "    # load 3 seconds of the file at sample rate=44100, mono.\n",
    "    signal, sr = librosa.load(path + filename, sr=SR, mono=True, duration=3)\n",
    "    return signal, sr\n",
    "\n",
    "# vectorize the function\n",
    "vec_load_audiot = np.vectorize(load_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb203a54",
   "metadata": {},
   "source": [
    "#### Extract the audio index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the audio index\n",
    "\n",
    "def extract_file_index(string):\n",
    "    return string.lower().split(' ')[0]\n",
    "\n",
    "# vectorize the function\n",
    "vec_extract_file_index = np.vectorize(extract_file_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a710de",
   "metadata": {},
   "source": [
    "#### Extract the bird species from the filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0752296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the bird species from the filename\n",
    "\n",
    "def extract_bird_name(string):\n",
    "    words = string.lower().split(' ')\n",
    "    bird=''\n",
    "    \n",
    "    for word in words:\n",
    "        if word in BIRDS:\n",
    "            bird = word\n",
    "\n",
    "    if bird=='':\n",
    "        bird='unknown'\n",
    "    return bird\n",
    "\n",
    "# vectorize the function\n",
    "vec_extract_bird_name = np.vectorize(extract_bird_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b468abd",
   "metadata": {},
   "source": [
    "#### Class Bird\n",
    "\n",
    "* The data contain arrays and lists, and cannot be held in a dataframe cell. The class is used to hold the data per bird.\n",
    "* The index of the bird is equal to the index in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ae4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bird:\n",
    "    def __init__(self, file_index, name):\n",
    "        self.name = name\n",
    "        self.file_index = file_index\n",
    "        self.signal = [] # the audio file raw data\n",
    "        self.sr = 0 # sample_rate\n",
    "        self.sc = [] # spectral centroid\n",
    "        self.stft = [] # short time fourier transform\n",
    "        self.Y = [] # spectrogram\n",
    "        self.loud_freqs = [] # the frequencies of the higher eights part of the db.\n",
    "        self.loudest_freq = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2245b2",
   "metadata": {},
   "source": [
    "### Create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b7929c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe\n",
    "df = pd.DataFrame({'file':files_wav})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ed5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a short file name and the bird species\n",
    "df['file_index'] = vec_extract_file_index(df['file'])\n",
    "df['bird']= vec_extract_bird_name(df['file'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf0aa1d",
   "metadata": {},
   "source": [
    "### Create birds objects and load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c854ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bird object\n",
    "\n",
    "def create_bird(indx, name, path, filename):\n",
    "    bird = Bird(indx, name)\n",
    "    bird.signal, bird.sr = load_audio(path, filename)\n",
    "    return bird\n",
    "\n",
    "# vectorize the function\n",
    "vec_create_bird = np.vectorize(create_bird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99763cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of 'Bird' objects.\n",
    "birds = vec_create_bird(df['file_index'], df['bird'], LOCAL_PATH_WAV, df['file'])\n",
    "len(birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afec1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# species proportion\n",
    "species_prop = df.groupby(['bird'])['file'].count().reset_index()\n",
    "species_prop.columns = ['bird', 'count']\n",
    "species_prop['percent'] = ((species_prop['count'] / df.shape[0]) *100).round(2)\n",
    "species_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt the graph\n",
    "fig = go.Figure(data=[go.Pie(labels=species_prop['bird'], values=species_prop['percent'])])\n",
    "fig.update_layout(title=\"Proportions of the various species of birds\")\n",
    "fig.show() \n",
    "#fig.write_image(\"images/propbird.png\") # used to save the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e87fd9",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c148d",
   "metadata": {},
   "source": [
    "#### Basic information of the audio files (all have the same sample rate, duration and no. of channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a257bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    df.loc[i, 'shape'] = birds[i].signal.shape\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that all the signals have the same shape\n",
    "print(df['shape'].min(), df['shape'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa506a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration in seconds of 1 sample\n",
    "sample_duration = 1 / SR\n",
    "print(f\"One sample lasts for {sample_duration:6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8015b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of samples in audio file (=shape)\n",
    "tot_samples = len(birds[0].signal)  \n",
    "tot_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ace976",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc4691",
   "metadata": {},
   "source": [
    "***Note:***\n",
    "\n",
    "The audio data is processed in two domains: *Time* and *Frequency*.\n",
    "- In the time domain we can see the amplitude changes over time. But, we have no information about the frequencies involved.\n",
    "- In the frequency domain we can see the frequencies involved. But we don't know when each frequency appear.\n",
    "- In order to combine the information from the two domains - we use spectrograms, which are like a heat map that show us the changes of the magnitude of each frequency over time.\n",
    "- As both scales of frequencies and magnitude (in decibels) are logarithmic, the values of the parameters will be mostly in power of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8195f",
   "metadata": {},
   "source": [
    "#### Time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4903c98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot data in time domain\n",
    "#counter=0 # used for saving the plots with unique name\n",
    "def plot_waves():\n",
    "    df_shape = 5  # first 5 birds\n",
    "    #df.shape[0] # - for all the birds\n",
    "\n",
    "    plt.figure(figsize=(15, 30))\n",
    "\n",
    "    for i in range(df_shape):\n",
    "        plt.subplot(df_shape, 1, i+1)\n",
    "        librosa.display.waveshow(birds[i].signal, alpha=0.5)\n",
    "        plt.ylim((-1, 1))\n",
    "        plt.title(birds[i].name)\n",
    "    #    plt.savefig(\"images/time\"+birds[i].name+str(counter)+\".png\") # used to save the image\n",
    "    #    counter+=1\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# diaplay the execution button            \n",
    "display(btn_time, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e852295",
   "metadata": {},
   "source": [
    "###### Conclusion:\n",
    "Although there are cases of repetitive patterns, there's not enough data to classify the birds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da41c5",
   "metadata": {},
   "source": [
    "#### Extracting Short-Time Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadbbe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SIZE = 2048\n",
    "HOP_SIZE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a52963",
   "metadata": {},
   "source": [
    "##### Visualizing the spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a spectrogram\n",
    "\n",
    "def plot_spectrogram(Y, sr, hop_length, y_axis=\"linear\", title='', counter=0):\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    librosa.display.specshow(Y, \n",
    "                             sr=sr, \n",
    "                             hop_length=hop_length, \n",
    "                             x_axis=\"time\", \n",
    "                             y_axis=y_axis,\n",
    "                            cmap='coolwarm')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.colorbar(format=\"%+2.f\")\n",
    "#    plt.savefig(\"images/spec\"+title+str(counter)+\".png\") # used to save the images\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfcb36e",
   "metadata": {},
   "source": [
    "##### Visualising spectrograms from different birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eecab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = range(len(birds[0].signal))\n",
    "t = librosa.frames_to_time(frames, hop_length=HOP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323da040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot=False # calculate only\n",
    "plot=True # calculate and plot the spectrograms\n",
    "\n",
    "counter=0 # used for saving the plots with unique name\n",
    "\n",
    "for b in birds:\n",
    "    # extract Short-Time Fourier Transform\n",
    "    S_b = librosa.stft(b.signal, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)\n",
    "\n",
    "    # calculate the spectrogram\n",
    "    Y_b = librosa.power_to_db(np.abs(S_b) ** 2)  #Y(m,k) = |S(m,k)|^2\n",
    "\n",
    "    if plot:\n",
    "        # plot the spectrogram\n",
    "        plot_spectrogram(Y_b, SR, HOP_SIZE, y_axis=\"log\", title=b.name, counter=counter)\n",
    "\n",
    "    counter+=1\n",
    "    # save to bird object\n",
    "    b.stft = S_b\n",
    "    b.Y = Y_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c0c5c6",
   "metadata": {},
   "source": [
    "As seen in the spectrograms, the typical loudest frequencies are about 256 Hz and higher (the dove has the lowest frequencies). So, we can assume that all the frequencies below that are background noise, and will be excluded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d6044",
   "metadata": {},
   "source": [
    "#### Add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c56679",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# find the loudest frequencies (the highest eighth)\n",
    "for b in birds:\n",
    "    hi=b.Y.max()-((b.Y.max()-b.Y.min())/8)\n",
    "    b.loud_freqs= (np.unique(np.where(b.Y > hi)[0])+1) * 16\n",
    "    b.loudest_freq = (np.where(b.Y == b.Y.max())[0]+1) * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# add features\n",
    "for i in df.index:\n",
    "    df.loc[i, 'hi_lim'] = birds[i].loud_freqs.max()\n",
    "    df.loc[i, 'lo_lim'] = np.maximum(birds[i].loud_freqs.min(), 192)\n",
    "    df.loc[i, 'loudest_freq'] = birds[i].loudest_freq\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9252a6c",
   "metadata": {},
   "source": [
    "#### Encode the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b00f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_dict = {'sunbird': 0, 'dove': 1, 'myna': 2, 'crow': 3}\n",
    "df['bird_code'] = df['bird'].map(bird_dict)\n",
    "df['buzz'] = df['bird_code'].astype(bool)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6508598",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training, test and validation \n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=RAND_STATE)\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.25, random_state=RAND_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9128936",
   "metadata": {},
   "source": [
    "#### Scale the numeric features\n",
    "\n",
    "*Note:*\n",
    "\n",
    "In the last version of features, there are only frequency based features, so there's no need to scale them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c2c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['hi_lim', 'lo_lim', 'loudest_freq']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f29f45",
   "metadata": {},
   "source": [
    "#### Check Outliers (train only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df_train[numeric].quantile(0.25)\n",
    "Q3 = df_train[numeric].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed160fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the value is an outlier\n",
    "(df_train[numeric] < (Q1 - 1.5 * IQR)) | (df_train[numeric] > (Q3 + 1.5 * IQR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92389734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric][df[numeric]==True].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4bffec",
   "metadata": {},
   "source": [
    "###### Conclusion:\n",
    "* There are no relevant outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7cfe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['file', 'file_index', 'bird', 'bird_code', 'buzz', 'shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff404dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare variables for features and target feature \n",
    "\n",
    "X_train = df_train.drop(cols_to_drop, axis=1)\n",
    "y_train = df_train['buzz']\n",
    "X_valid = df_valid.drop(cols_to_drop, axis=1)\n",
    "y_valid = df_valid['buzz']\n",
    "X_test = df_test.drop(cols_to_drop, axis=1)\n",
    "y_test = df_test['buzz']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape) \n",
    "print(X_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34842bb5",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf75502",
   "metadata": {},
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8001697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_score(model, X_valid, y_valid):\n",
    "    predicted_valid = model.predict(X_valid)\n",
    "    precision = skm.precision_score(y_valid, predicted_valid)\n",
    "    recall = skm.recall_score(y_valid, predicted_valid)\n",
    "    \n",
    "    print('accuracy_score', skm.accuracy_score(y_valid, predicted_valid).round(3)) \n",
    "    print('f1_score', skm.f1_score(y_valid, predicted_valid).round(3))    \n",
    "    print('Recall:', recall.round(3))\n",
    "    print('Precision:', precision.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a060f28",
   "metadata": {},
   "source": [
    "### Base line model (constant True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636d632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid\n",
    "print('f1_score', skm.f1_score(y_valid, np.ones(y_valid.shape)).round(3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "print('f1_score', skm.f1_score(y_test, np.ones(y_test.shape)).round(3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07d0569",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035702df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit, predict and score logistic regression\n",
    "model = LogisticRegression(random_state=RAND_STATE, solver='liblinear', multi_class='auto')\n",
    "lg = model.fit(X_train, y_train)\n",
    "predict_and_score(lg, X_valid, y_valid)\n",
    "\n",
    "# save the model\n",
    "dump(model, 'bird-lg.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf3344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test log_reg\n",
    "predict_and_score(lg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a3ca31",
   "metadata": {},
   "source": [
    "###### Conclusion:\n",
    "* The validation set has worse results than just guessing.\n",
    "* The test set has much better results than the base line model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723b7b31",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dad7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "# shuffle \n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b9b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones]) \n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones]) \n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a1216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_f1 (model.fit and calculate F1)\n",
    "#* basic: (model, features_train, target_train)\n",
    "#* upsample: (model,features_upsampled, target_upsampled)\n",
    "#* downsample: (model, features_downsampled, target_downsampled)\n",
    "\n",
    "def fit_f1(model, X_train, y_train, X_val_tst, y_val_tst):\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted_valid = model.predict(X_val_tst)\n",
    "\n",
    "    print('F1:', skm.f1_score(y_val_tst, predicted_valid).round(3)) # binary\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510cb8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    model = DecisionTreeClassifier(random_state=RAND_STATE, class_weight='balanced', max_depth=i)\n",
    "    print(i, ':') \n",
    "    dtc= fit_f1(model, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8129092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the model with optimized hyper parameters\n",
    "model = DecisionTreeClassifier(random_state=RAND_STATE, class_weight='balanced', max_depth=1)\n",
    "dtc= fit_f1(model, X_train, y_train, X_valid, y_valid)\n",
    "predict_and_score(dtc, X_valid, y_valid)\n",
    "\n",
    "# save the model\n",
    "dump(dtc, 'bird-dtc.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd8e09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test DecisionTreeClassifier\n",
    "predict_and_score(dtc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d39cbaf",
   "metadata": {},
   "source": [
    "###### Conclusions:\n",
    "* The F1 score is higher than just guessing - both the valid and the test sets.\n",
    "* The perfect precision shows that the model doesn't drive away any welcome bird, but the recall shows that there are cases in which an unwelcome bird is not driven away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e9104",
   "metadata": {},
   "source": [
    "#### Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a7c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_upsampled, y_upsampled = upsample(X_train, y_train, 4)\n",
    "print(X_upsampled.shape)\n",
    "print(y_upsampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a38e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = fit_f1(model, X_upsampled, y_upsampled, X_valid, y_valid)\n",
    "predict_and_score(dtc, X_valid, y_valid)\n",
    "\n",
    "# save the model\n",
    "dump(dtc, 'bird-dtc-up.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a13374",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_score(dtc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64accaf",
   "metadata": {},
   "source": [
    "###### Conclusions:\n",
    "* The perfect precision shows that the model doesn't drive away any welcome bird, but the recall shows that there are cases in which an unwelcome bird is not driven away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0082f123",
   "metadata": {},
   "source": [
    "#### Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92564af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_downsampled, y_downsampled = downsample(X_train, y_train, 0.8)\n",
    "\n",
    "print(X_downsampled.shape)\n",
    "print(y_downsampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd322090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid\n",
    "dtc=fit_f1(model,X_downsampled, y_downsampled, X_valid, y_valid)\n",
    "predict_and_score(dtc, X_valid, y_valid)\n",
    "\n",
    "# save the model\n",
    "dump(dtc, 'bird-dtc-down.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "dtc=fit_f1(model,X_downsampled, y_downsampled, X_test, y_test)\n",
    "predict_and_score(dtc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58609c99",
   "metadata": {},
   "source": [
    "###### Conclusions:\n",
    "* With downsampling we got perfect results in the test set. But, since there are relatively few samples, it has to be checked on much larger amount of samples before celebrating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1ecbbe",
   "metadata": {},
   "source": [
    "#### Threshold (on the Decision-Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5767297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold - valid\n",
    "model.fit(X_train, y_train)\n",
    "probabilities_valid = model.predict_proba(X_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "for threshold in np.arange(0, 0.9, 0.1):\n",
    "    predicted_valid = probabilities_one_valid > threshold \n",
    "    precision = skm.precision_score(y_valid, predicted_valid)\n",
    "    recall = skm.recall_score(y_valid, predicted_valid)\n",
    "\n",
    "\n",
    "    print('Threshold = {:.2f} | Precision = {:.3f}, Recall = {:.3f}, F1 = {:.3f}'.format(\n",
    "        threshold, precision, recall, (2 * precision * recall/(precision + recall))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6478dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold - test\n",
    "model.fit(X_train, y_train)\n",
    "probabilities_test = model.predict_proba(X_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "\n",
    "threshold = 0.2\n",
    "predicted_test = probabilities_one_test > threshold \n",
    "precision = skm.precision_score(y_test, predicted_test)\n",
    "recall = skm.recall_score(y_test, predicted_test)\n",
    "\n",
    "\n",
    "print('Threshold = {:.2f} | Precision = {:.3f}, Recall = {:.3f}, F1 = {:.3f}'.format(\n",
    "        threshold, precision, recall, (2 * precision * recall/(precision + recall))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40147d0d",
   "metadata": {},
   "source": [
    "###### Conclusions:\n",
    "* The perfect precision shows that the model doesn't drive away any welcome bird, but the recall shows that there are cases in which an unwelcome bird is not driven away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a1b2f6",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe71201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "fpr, tpr, thresholds = skm.roc_curve(y_test, probabilities_one_test)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "# ROC curve for random model (looks like a straight line)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "plt.title(\"ROC curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e84eaff",
   "metadata": {},
   "source": [
    "###### Conclusion:\n",
    "* The ROC curve high results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f7ec74",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5, 50, 5):\n",
    "    model = RandomForestClassifier(random_state=RAND_STATE, n_estimators=i)\n",
    "    rf= fit_f1(model, X_train, y_train, X_valid, y_valid)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=RAND_STATE, n_estimators=5)\n",
    "rf= fit_f1(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# save the model\n",
    "dump(rf, 'bird-rf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904b4ff",
   "metadata": {},
   "source": [
    "###### Conclusions:\n",
    "* Running the test set results perfect F1 score (better than the valid). In this case, even low number of estimators gives perfect results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dafd8c",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "features = data.drop(cols_to_drop, axis=1)\n",
    "target = data['buzz']\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=RAND_STATE)\n",
    "\n",
    "# calculate scores by calling cross_value_score function \n",
    "scores=cross_val_score(model, features, target, cv=10) \n",
    "final_score=sum(scores)/len(scores)\n",
    "print('Average model evaluation score:', final_score.round(3))\n",
    "\n",
    "# save the model\n",
    "dump(model, 'bird-cv.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcecb61",
   "metadata": {},
   "source": [
    "###### Conclusions:\n",
    "* The CV model has lower results than the tree's model, and not much higher than the base line. but, it is less sensitive to variance in the sets as it shuffles the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896364f1",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "* Looking at the results - the perfect model for this case is a Decision tree classifier with downsampling. It has perfect results.\n",
    "* Considering  that there are only about a hundred samples, the result should be taken as limited - but there's a potential for further research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf5734",
   "metadata": {},
   "source": [
    "## Run the model on a Raspberry Pi\n",
    "* Run scarecrow.py on the Raspberry Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb6812",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [xeno-canto.org](https://xeno-canto.org).\n",
    "* Videos by Valerio Velardo - 'The Sound of AI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4143e8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabecfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "434px",
    "left": "243px",
    "top": "499px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
